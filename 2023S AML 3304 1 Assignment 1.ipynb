{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Necessary Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/krishnamenon/anaconda3/lib/python3.7/site-packages (3.4)\n",
      "Requirement already satisfied: six in /Users/krishnamenon/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in /Users/krishnamenon/anaconda3/lib/python3.7/site-packages (from nltk) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/Users/krishnamenon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "In the quiet of the morning, the sun kissed the earth, painting the sky in hues of gold and pink. Nature awakened, its symphony of birdsong filling the air, reminding us of the beauty that surrounds us, inviting us to embrace each day with gratitude and wonder.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"''\", 'in', 'the', 'quiet', 'of', 'the', 'morning', ',', 'the', 'sun', 'kissed', 'the', 'earth', ',', 'painting', 'the', 'sky', 'in', 'hues', 'of', 'gold', 'and', 'pink', '.', 'nature', 'awakened', ',', 'its', 'symphony', 'of', 'birdsong', 'filling', 'the', 'air', ',', 'reminding', 'us', 'of', 'the', 'beauty', 'that', 'surrounds', 'us', ',', 'inviting', 'us', 'to', 'embrace', 'each', 'day', 'with', 'gratitude', 'and', 'wonder', '.', \"''\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/krishnamenon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "tokens = nltk.word_tokenize(sample_text.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. N-Gram Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'collections.Counter'>, {\"''\": Counter({'in': 1}), 'in': Counter({'the': 1, 'hues': 1}), 'the': Counter({'quiet': 1, 'morning': 1, 'sun': 1, 'earth': 1, 'sky': 1, 'air': 1, 'beauty': 1}), 'quiet': Counter({'of': 1}), 'of': Counter({'the': 2, 'gold': 1, 'birdsong': 1}), 'morning': Counter({',': 1}), ',': Counter({'the': 1, 'painting': 1, 'its': 1, 'reminding': 1, 'inviting': 1}), 'sun': Counter({'kissed': 1}), 'kissed': Counter({'the': 1}), 'earth': Counter({',': 1}), 'painting': Counter({'the': 1}), 'sky': Counter({'in': 1}), 'hues': Counter({'of': 1}), 'gold': Counter({'and': 1}), 'and': Counter({'pink': 1, 'wonder': 1}), 'pink': Counter({'.': 1}), '.': Counter({'nature': 1, \"''\": 1}), 'nature': Counter({'awakened': 1}), 'awakened': Counter({',': 1}), 'its': Counter({'symphony': 1}), 'symphony': Counter({'of': 1}), 'birdsong': Counter({'filling': 1}), 'filling': Counter({'the': 1}), 'air': Counter({',': 1}), 'reminding': Counter({'us': 1}), 'us': Counter({'of': 1, ',': 1, 'to': 1}), 'beauty': Counter({'that': 1}), 'that': Counter({'surrounds': 1}), 'surrounds': Counter({'us': 1}), 'inviting': Counter({'us': 1}), 'to': Counter({'embrace': 1}), 'embrace': Counter({'each': 1}), 'each': Counter({'day': 1}), 'day': Counter({'with': 1}), 'with': Counter({'gratitude': 1}), 'gratitude': Counter({'and': 1}), 'wonder': Counter({'.': 1})})\n"
     ]
    }
   ],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq = defaultdict(Counter)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    bigram_freq[w1][w2] += 1\n",
    "\n",
    "print(bigram_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generating Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earth , its symphony of the\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed, n_words):\n",
    "    result = [seed]\n",
    "    for _ in range(n_words):\n",
    "        next_word_options = bigram_freq[result[-1]]\n",
    "        next_word = random.choices(list(next_word_options.keys()), list(next_word_options.values()))[0]\n",
    "        result.append(next_word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "generated_text = generate_text('earth', 5)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more text to the model,train it, and ask more questions to get better answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_text = \"In the quiet of the morning, the sun kissed the earth, painting the sky in hues of gold and pink. Nature awakened, its symphony of birdsong filling the air, reminding us of the beauty that surrounds us, inviting us to embrace each day with gratitude and wonder.\"\n",
    "new_text = \"Amidst the gentle breeze, the fragrance of blooming flowers danced, intertwining with the earthy scent of dew-kissed grass. The world seemed alive, vibrant with possibilities waiting to be seized. And in that moment, we knew that today held the promise of endless opportunities and the potential for extraordinary moments.\"\n",
    "combined_text = old_text + \" \" + new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = sent_tokenize(combined_text)\n",
    "word_tokens = [word_tokenize(t) for t in sent_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a trigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train model with more text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generate text with various questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the importance\n",
      "Answer: <s> In the quiet of the beauty that surrounds us , inviting us to embrace each day with gratitude and\n",
      "\n",
      "\n",
      "Question: How does it work\n",
      "Answer: its symphony of birdsong filling the air , reminding us of the morning , the sun kissed the earth ,\n",
      "\n",
      "\n",
      "Question: What are the benefits\n",
      "Answer: Nature awakened , its symphony of birdsong filling the air , reminding us of the beauty that surrounds us ,\n",
      "\n",
      "\n",
      "Question: How can I improve\n",
      "Answer: <s> In the quiet of the morning , the sun kissed the earth , painting the sky in hues of\n",
      "\n",
      "\n",
      "Question: What should I consider\n",
      "Answer: . </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, num_words, model):\n",
    "    word_list = model.generate(num_words, text_seed=prompt.split())\n",
    "    response = ' '.join(word_list)\n",
    "    return response\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What is the importance\",\n",
    "    \"How does it work\",\n",
    "    \"What are the benefits\",\n",
    "    \"How can I improve\",\n",
    "    \"What should I consider\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {generate_text(question, 20, model)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple LLM (language model) using the nltk library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text = \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence \\\n",
    "concerned with the interactions between computers and human language. In particular, it focuses on programming \\\n",
    "computers to process and analyze large amounts of natural language data.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigrams and their frequency distribution\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "bigram_freq_dist = FreqDist(bigrams)\n",
    "\n",
    "# Prepare the dataset for training\n",
    "train_data, padded_sents = padded_everygram_pipeline(2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram model\n",
    "model = MLE(2)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is natural language processing?\n",
      "A: processing l i s </s> n g u t u\n",
      "\n",
      "Q: How does artificial intelligence relate to linguistics?\n",
      "A: How </s> o </s> t a n c i c\n",
      "\n",
      "Q: Can computers understand human language?\n",
      "A: language n </s> l y z e r a n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, num_words, seed_word):\n",
    "    sentence = [seed_word]\n",
    "    for _ in range(num_words - 1):\n",
    "        next_word = model.generate(1, text_seed=sentence)\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example questions to the model\n",
    "questions = [\n",
    "    \"What is natural language processing?\",\n",
    "    \"How does artificial intelligence relate to linguistics?\",\n",
    "    \"Can computers understand human language?\",\n",
    "]\n",
    "\n",
    "# Generate answers for the questions\n",
    "for question in questions:\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    seed_word = choice(tokens)\n",
    "    generated_sentence = generate_sentence(model, 10, seed_word)\n",
    "    print(f\"Q: {question}\\nA: {generated_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with more datasets, model architectures, and training techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "text = \"Natural Language Processing (NLP) encompasses a wide range of techniques and methodologies.\\\n",
    "It involves processing and understanding natural language input from humans and generating natural language output \\\n",
    "for effective communication. NLP algorithms leverage machine learning, statistical modeling, and linguistic rules \\\n",
    "to perform tasks like text classification, information extraction, sentiment analysis, question answering, \\\n",
    "and language generation. NLP finds applications in various domains, including chatbots, virtual assistants, \\\n",
    "language translation, sentiment analysis in social media, customer support systems, and content recommendation engines.\\\n",
    "Its goal is to bridge the gap between human language and machine understanding, enabling computers to comprehend, process, and generate human-like language.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate triigrams and their frequency distribution\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram model\n",
    "model = MLE(2)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is Natural Language Processing (NLP)?\n",
      "A: NLP L P\n",
      "\n",
      "Q: How does NLP relate to artificial intelligence?\n",
      "A: NLP t h e\n",
      "\n",
      "Q: What are the main objectives of NLP?\n",
      "A: the L P\n",
      "\n",
      "Q: What are some common applications of NLP\n",
      "A: applications t\n",
      "\n",
      "Q: What are the components involved in NLP?\n",
      "A: What L P\n",
      "\n",
      "Q: How does NLP enable computers to process and understand human language?\n",
      "A: and a t e\n",
      "\n",
      "Q: What techniques and methodologies are used in NLP?\n",
      "A: in s\n",
      "\n",
      "Q: Can you provide examples of tasks that NLP can perform?\n",
      "A: tasks m a t\n",
      "\n",
      "Q: In which domains is NLP commonly applied?\n",
      "A: domains\n",
      "\n",
      "Q: What is the ultimate goal of NLP?\n",
      "A: goal i m a t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, num_words, seed_word):\n",
    "    sentence = [seed_word]\n",
    "    for _ in range(num_words - 1):\n",
    "        next_word = model.generate(1, text_seed=sentence)\n",
    "        sentence.append(next_word)\n",
    "    sentence = [word for word in sentence if word != '</s>']\n",
    "    sentence = [word for word in sentence if word != '<s>']\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example questions to the model\n",
    "questions = [\n",
    "    \"What is Natural Language Processing (NLP)?\",\n",
    "    \"How does NLP relate to artificial intelligence?\",\n",
    "    \"What are the main objectives of NLP?\",\n",
    "    \"What are some common applications of NLP\",\n",
    "    \"What are the components involved in NLP?\",\n",
    "    \"How does NLP enable computers to process and understand human language?\",\n",
    "    \"What techniques and methodologies are used in NLP?\",\n",
    "    \"Can you provide examples of tasks that NLP can perform?\",\n",
    "    \"In which domains is NLP commonly applied?\",\n",
    "    \"What is the ultimate goal of NLP?\"\n",
    "]\n",
    "\n",
    "# Generate answers for the questions\n",
    "for question in questions:\n",
    "    tokens = nltk.word_tokenize(question)\n",
    "    seed_word = choice(tokens)\n",
    "    generated_sentence = generate_sentence(model, 10, seed_word)\n",
    "    print(f\"Q: {question}\\nA: {generated_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
